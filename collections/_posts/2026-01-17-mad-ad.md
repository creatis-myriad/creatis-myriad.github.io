---
layout: review
title: "MAD-AD: Masked Diffusion for Unsupervised Brain Anomaly Detection"
tags: Diffusion models, anomaly detection
author: "Olivier Bernard"
cite:
    authors: "Farzad Beizaee, Gregory Lodygensky, Christian Desrosiers, Jose Dolz"
    title: "MAD-AD: Masked Diffusion for Unsupervised Brain Anomaly Detection"
    venue: "IPMI 2025"
pdf: "https://arxiv.org/pdf/2502.16943"
---

# Notes

* Link to the code [here](https://github.com/farzad-bz/MAD-AD)

# Diffusion model reminders

The full presentation, including links to the diffusion model (DDPM), is available [here](https://olivier-bernard-creatis.github.io//files//research-sfds-bernard-2025.pdf) 

<div style="text-align:center">
<img src="/collections/images/mad-ad/diffusion-model-1.jpg" width=700></div>

<div style="text-align:center">
<img src="/collections/images/mad-ad/diffusion-model-2.jpg" width=700></div>

<div style="text-align:center">
<img src="/collections/images/mad-ad/diffusion-model-3.jpg" width=700></div>

&nbsp;

# Highlights

* Extending the idea proposed in the THOR method [1] to the training procedure 
* Learning to remove regions with anomalies of varying sizes using a diffusion process
* Evaluation from three public datasets: `IXI Dataset` (brain MRI scans from
approximately 600 healthy subjects), `ATLAS 2.0` (655 T1-weighted
MRI scans accompanied by expert-segmented lesion masks), and `BraTS'21` (1251 brain scans across four modalities: T1-weighted, contrast-
enhanced T1-weighted - T1CE, T2-weighted, and T2 Fluid Attenuated Inversion
Recovery - FLAIR)

# Motivations

* Removing the need for forward and reverse processes in diffusion-based anomaly detection avoids several limitations, including feature degradation during forward diffusion and a trade-off between localization accuracy and removable anomaly size.

# Overall idea

* The method is based on the following hypothesis: starting from a VAE trained exclusively on normal subjects, a region containing abnormalities is efficiently represented as noise in the corresponding latent space.
* Using a dataset of healthy subjects, relevant synthetic anomalies can be introduced by adding Gaussian noise of varying intensity to randomly selected regions via a forward diffusion process, and subsequently learning to remove them through a reverse diffusion process.

# Key ideas

* The diffusion process can be revisited by estimating $$x_0$$, denoted as $$\hat{x}_0$$, at any time step $$t$$ using the following equations.

## DDPM

* Computation of the estimated $$\hat{x}_0(x_t,t)$$ from $$\epsilon_\theta(x_t,t)$$
$$\textcolor{red}{\hat{x}_0(x_t,t) = \frac{1}{\sqrt{\bar{\alpha}_t}} \left(x_t - \sqrt{1-\bar{\alpha}_t}\, \epsilon_\theta(x_t,t) \right)}$$
* Computation of $$\epsilon_\theta(x_t,t)$$ from the estimated $$\hat{x}_0(x_t,t)$$
$$\epsilon_\theta(x_t,t) = \frac{x_t - \sqrt{\bar{\alpha}_t}\,\hat{x}_0(x_t,t)} {\sqrt{1-\bar{\alpha}_t}}$$

* The reverse process that links $$x_{t-1}$$ with $$x_t$$ can be rewritten as:
$$x_{t-1} = \left(\frac{\sqrt{\bar{\alpha}_{t-1}}\,\beta_t}{1-\bar{\alpha}_t}\,\hat{x}_0 + \frac{\sqrt{\alpha_t}\left(1-\bar{\alpha}_{t-1}\right)}{1-\bar{\alpha}_t}\,x_t\right) + \sigma_t \, \epsilon$$

<div style="text-align:center">
<img src="/collections/images/mad-ad/ddpm-reverse-process-revisited.jpg" width=700></div>


## DDIM

* DDIM is commonly used to reconstruct images through a deterministic sampling process
* The following DDIM expression is always true:
$$x_{t-1} = \sqrt{\bar{\alpha}_{t-1}}\,\hat{x}_0 + \sqrt{1-\bar{\alpha}_{t-1}}\,\epsilon_\theta$$
* Using the relation that links $$\epsilon_{\theta}$$ with $$\hat{x}_0$$, this expression can be rewritten as:
$$\textcolor{red}{x_{t-1} = \sqrt{\bar{\alpha}_{t-1}}\,\hat{x}_0 + \sqrt{1-\bar{\alpha}_{t-1}}\,
\left(\frac{x_t-\sqrt{\bar{\alpha}_t}\,\hat{x}_0}
{\sqrt{1-\bar{\alpha}_t}}\right)}$$

# Methodology

## Training procedure

### Modeling the normal feature space

* Excusively healthy subjects are used during training: $$\{x^{(i)}\}_{i=1}^{N}$$ with $$x^{(i)} \in \mathbb{R}^{H \times W \times C}$$ 
* A pre-trained variational auto-encoder $$V_{E,\phi}$$ is fine-tuned on the dataset and then frozen for the rest of the process
* Each input image $$x^{(i)}$$ are mapped to its latent space representation $$z^{(i)} = V_{E,\phi}\left(x^{(i)}\right)$$, where $$z^{(i)} \in \mathbb{R}^{H' \times W' \times C'}$$

<div style="text-align:center">
<img src="/collections/images/mad-ad/VAE-procedure.jpg" width=300></div>

&nbsp;

### Random masking

* The latent features of a normal input sample $$z_0$$ are spatially partitioned into non-overlapping patches using a random mask $$M \in [0,1]^{H' \times W'}$$
* This random mask simulates regions with abnormalities
  
### Forward process

* The forward diffusion process gradually applies noise to the masked patches of sample $$z_0$$ for $$t$$ time steps to generate samples $$z_t$$ with $t \in [1, T]$

$$z_t = \left( \sqrt{\bar{\alpha_t}} \, z_0 + \sqrt{1-\bar{\alpha_t}} \, \epsilon_t \right) \odot M + z_0 \odot \left( 1 - M \right)$$

where $$\epsilon_t \sim \mathcal{N}(0,I)$$, $$\alpha_t = 1 - \beta_t$$ and $$\bar{\alpha_t} = \prod_{i=1}^{T} \alpha_i$$

<div style="text-align:center">
<img src="/collections/images/mad-ad/forward-process-with-masking.jpg" width=600></div>

&nbsp;

### Reverse process

* The reverse process aims to recover the original data $$z_0$$ by gradually removing the noise  
* Given the sample $$z_t$$ at step $$t$$ and mask $$M$$ at spatial location $$k$$, the reverse process can be modeled as: 

$$p\left(z^k_{t-1} \mid z^k_t\right) = \begin{cases}
\mathcal{N}\left( \mu_{\theta}(z^k_t,t), \, \beta_t \mathbf{I} \right), &\textit{if  } M^k=1 \\
z^k_t, & \textit{otherwise}
\end{cases}$$
  
> $$\mu_{\theta}(z_t,t)$$ is a trainable function, which can be reparameterized as a predicted noise $$\epsilon$$ or a predicted clean image $$z_0$$

* Due to the incorporated random masking strategy, the predicted clean image formulation is chosen:

$$\mu_{\theta}(z_t,t) = \frac{\sqrt{\bar{\alpha}_{t-1}} \, \beta_t}{1-\bar{\alpha}_t} \, \textcolor{red}{f_{\theta,z_0}(z_t,t)} + \frac{\sqrt{\alpha_t}\,(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t} \, z_t$$

where $$f_{\theta,z_0}(z_t,t)$$ is a trainable function that predicts $$\hat{z}_0$$ at time $$t$$, given $$z_t$$. 

* The following scheme is applied only to the masked region:

<div style="text-align:center">
<img src="/collections/images/mad-ad/mad-ad-diagram-reverse-process-revisited.jpg" width=700></div>

* $$f_{\theta,z_0}$$ is a neural network that is trained using a simple mean-square error loss between $$z_0$$ and the predicted image without any noise:

$$\displaystyle \min_{\theta} \; \mathbb{E}_{z_0 \sim q(z_0),\, \epsilon,\, t} \left[ \left\| z_0 - f_{\theta, z_0}(z_t, t) \right\|_2^2\right]$$

### Mask prediction

* The location of the anomalous regions needs to be estimated during inference 
* An additional head $$f_{\theta,M}$$ is added to the diffusion model to predict the mask used in the forward diffusion process
* The final loss function is given as: 
$$\displaystyle \min_{\theta} \; \mathbb{E}_{z_0 \sim q(z_0),\, \epsilon,\, t} \left[ \left\| z_0 - f_{\theta, z_0}(z_t, t) \right\|_2^2\right] + \lambda \, \mathcal{L}_{\mathrm{BCE}}\!\left(M, f_{\theta, M}(z_t, t)\right)$$

  where $$\lambda$$ is a hyper-parameter that balances the contributions of the two terms

<div style="text-align:center">
<img src="/collections/images/mad-ad/mad-ad-training-procedure.jpg" width=700></div>


## Inference

### Recovering normal images

* Let $$\{ x'^{(i)} \}_{i=1}^N$$ denote the test set at inference time, which consists of samples with potential anomalies
* These images are first map into the latent space using $$V_{E,\phi}$$

> The latent space of an anomalous
image is treated as step $$T$$ of a masked forward diffusion process applied on its normal counterpart, i.e., $$z'_T = V_{E,\phi}(x'_T)$$

* By predicting the mask that corresponds to the anomaly location and the reconstructed $$\hat{z}'_0$$ at each time-step $$t$$, using the expression of $$p(z^k_{t-1} \mid z^k_t)$$, it is possible to progressively correct the anomaly regions and obtain the normal counterpart $$(z'_T \rightarrow z'_0)$$ while preserving fine details of the normal regions
&nbsp;

* One drawback of sampling with DDPM is that it requires many
reverse sampling steps to obtain the normal version
* A DDIM framework is used instead to make the reverse process more deterministic and require fewer sampling steps
* The reverse process of DDIM is modified for the MAD-AD model as:

$$
\begin{aligned}
\tilde{z}'_{t-1}
&=
\underbrace{B\!\left(\textcolor{red}{f_{\theta,M}(z'_t)}\right)}_{\text{predicted mask}}
\Big(
\sqrt{\bar{\alpha}_{t-1}}\, 
\underbrace{\textcolor{red}{f_{\theta,z_0}(z'_t)}}_{\text{predicted } \hat{z}'_0}
+
\underbrace{\sqrt{1 - \bar{\alpha}_{t-1}}\, \textcolor{red}{\hat{\epsilon}_t(z'_t)}}_{\text{direction pointing to } z'_t}
+
\sigma_t \epsilon'_t
\Big)
\\
&\quad
+
\left(
1 - B\!\left(\textcolor{red}{f_{\theta,M}(z'_t)}\right)
\right) z'_t
\end{aligned}
$$

  where $$\hat{\epsilon}_t(z'_t) = \frac{z'_t - \sqrt{\bar{\alpha}_t}\,\textcolor{red}{f_{\theta,z_0}}(z'_t)} {\sqrt{1-\bar{\alpha}_t}}$$

<div style="text-align:center">
<img src="/collections/images/mad-ad/mad-ad-inference-procedure.jpg" width=700></div>


### Anomaly localization

* The discrepancy between the input image and its reconstructed normal counterpart is used to localize anomalies 
* Using the normal latent embedding $$\hat{z}'_0$$, the normal sample is reconstructed in the image-space as: $$\hat{x}'_0 = V_{D,\phi}(\hat{z}'_0)$$, where $$V_{D,\phi}$$ is the pre-trained VAE decoder
* The predicted anomaly map is then given by

$$a = G * \min \left( \left\| \hat{x}'_0 - x'_0\right\|_2^2, \gamma \right) / \gamma$$

  where $$G$$ is a Gaussian kernel to smooth the predicted mask, $$âˆ—$$ is the convolution operator, and $$\gamma$$ is a threshold designed to prevent assigning excessive weight to patches with significant deviations

# Experiments

* Evaluation on 8 public datasets (small images): MNIST, Fashion-MNIST, 20Newsgroups, Omniglot, Omniglot-5, CIFAR-10 and CIFAR-100, CelebA
* Comparison with baseline methods: VAE (non-hierarchical method) and LadderVAE (sequential method)
* The dimension of all latent embeddings $$z = \{z_0, \cdots, z_V \}$$ is the same and is equal to 8 for MNIST, Fashion, and Omniglot, to 4 for 20Newsgroups, and to 64 for CIFAR-10, CIFAR-100, and CelebA
* The maximum depth of the tree is set to 6 for all datasets, except 20Newsgroups where depth was increased to 7 to capture more clusters
* To compute DP and LP, the tree is allowed to grow to a maximum of 30 leaves for 20Newsgroups and CIFAR-100, and 20 for the rest, while for ACC and NMI the number of leaves is set to the number of true classes
* The transformations consist of one-layer MLPs of size 128 and the routers of two-layers of size 128 for all datasets except for the real-world imaging data where the size of the MLP is increased to 512
* the encoder and decoders consist of simple CNNs and MLPs
* The trees are trained for $$N_t = 150$$ epochs at each growth step, and the final tree is finetuned for $$N_f = 200$$ epochs
* All experiments were run on RTX3080 GPUs
* Training TreeVAE with 10 leaves on MNIST, Fashion-MNIST, and Omniglot-50 takes between 1h and 2h, Omniglot-5 30 minutes, CIFAR-10 5h
* Training TreeVAE with 20 leaves on 20Newsgroup takes approximately 30 minutes, and on CIFAR-100 9h
* Training TreeVAE on CelebA takes approx 8h

&nbsp;

# Results

## Clustering performances

* Assessement of the hierarchical clustering performance by computing dendrogram purity (DP) and leaf purity (LP), , as defined by [Kobren et al.](https://nmonath.github.io/talks/perch_data_science_symposium17.pdf), and the more standard clustering metrics: accuracy (ACC) and normalized mutual information (NMI), by setting the number of leaves for TreeVAE and for the baselines to the true number of clusters

<div style="text-align:center">
<img src="/collections/images/tree-vae/tree-vae-result-clustering-performance.jpg" width=700></div>

&nbsp;

## Generative capacities

* Compute the approximated true log-likelihood (LL) calculated using 1000 importance-weighted samples, together with the ELBO and the reconstruction loss (RL)

<div style="text-align:center">
<img src="/collections/images/tree-vae/tree-vae-result-generative-capacity.jpg" width=700></div>

&nbsp;

## Discovery of Hierarchies

* In addition to solely clustering data, TreeVAE is able to discover meaningful hierarchical relations between the clusters, thus allowing for more insights into the dataset

<div style="text-align:center">
<img src="/collections/images/tree-vae/tree-vae-result-figure4.jpg" width=700></div>

&nbsp;

<div style="text-align:center">
<img src="/collections/images/tree-vae/tree-vae-result-figure6.jpg" width=500></div>

&nbsp;

<div style="text-align:center">
<img src="/collections/images/tree-vae/tree-vae-result-figure7.jpg" width=700></div>

&nbsp;


# Conclusions

* This paper presents an unsupervised clustering-based VAE method
* The model architecture / design is strongly inspired by decision trees
* Results vary with key parameters (max number of leafs, depth, different thresholds) that need to be manually selected
* The method seems computationally expensive

# Reference

[1] Cosmin I. Bercea, Benedikt Wiestler, Daniel Rueckert, and Julia A. Schnabel. [Diffusion Models with Implicit Guidance for Medical Anomaly Detection.](https://papers.miccai.org/miccai-2024/paper/1315_paper.pdf), MICCAI 2024
